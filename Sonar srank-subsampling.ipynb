{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e121f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "from ripser import ripser\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "from persim import plot_diagrams\n",
    "import persim\n",
    "import glob\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "import random\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "\n",
    "import umap\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import stablerank.srank as sr\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0391a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-01-29 02:30:51--  https://unirioja-my.sharepoint.com/:x:/g/personal/adines_unirioja_es/EbHRGswx8pxPtp1ZDF1l28YB_qXGIAX7qzbn5II29kLjGA?download=1\n",
      "Resolving unirioja-my.sharepoint.com (unirioja-my.sharepoint.com)... 13.107.138.10, 13.107.136.10\n",
      "Connecting to unirioja-my.sharepoint.com (unirioja-my.sharepoint.com)|13.107.138.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /personal/adines_unirioja_es/Documents/sonar.csv?ga=1 [following]\n",
      "--2024-01-29 02:30:52--  https://unirioja-my.sharepoint.com/personal/adines_unirioja_es/Documents/sonar.csv?ga=1\n",
      "Reusing existing connection to unirioja-my.sharepoint.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87776 (86K) [application/octet-stream]\n",
      "Saving to: 'sonar.csv'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 58% 14,7M 0s\n",
      "    50K .......... .......... .......... .....                100% 44,3M=0,004s\n",
      "\n",
      "2024-01-29 02:30:52 (20,4 MB/s) - 'sonar.csv' saved [87776/87776]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://unirioja-my.sharepoint.com/:x:/g/personal/adines_unirioja_es/EbHRGswx8pxPtp1ZDF1l28YB_qXGIAX7qzbn5II29kLjGA?download=1 -O sonar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697a1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prima():\n",
    "  df=pd.read_csv(\"sonar.csv\", sep=',',header=None)\n",
    "  df1 = df.iloc[:,:-1]\n",
    "  df2=df.iloc[:,-1]\n",
    "  return df1.values,df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45eec013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dataset(data,target,n_labeled=25):\n",
    "  unos=np.where(target==1)[0]\n",
    "  ceros=np.where(target==0)[0]\n",
    "\n",
    "  datos_uno=np.array(data)[unos]\n",
    "  datos_cero=np.array(data)[ceros]\n",
    "\n",
    "  unos_valid=int((len(list(unos))-n_labeled)*0.2)\n",
    "  ceros_valid=int((len(list(ceros))-n_labeled)*0.2)\n",
    "\n",
    "  random.seed(15)\n",
    "  indices_unos=random.sample(list(unos),n_labeled+unos_valid)\n",
    "\n",
    "  random.seed(10)\n",
    "  indices_ceros=random.sample(list(ceros),n_labeled+ceros_valid)\n",
    "\n",
    "\n",
    "  puntos_unos=np.array(data)[indices_unos[0:n_labeled]]\n",
    "  puntos_ceros=np.array(data)[indices_ceros[0:n_labeled]]\n",
    "\n",
    "  puntos_unos_valid=np.array(data)[indices_unos[n_labeled:]]\n",
    "  puntos_ceros_valid=np.array(data)[indices_ceros[n_labeled:]]\n",
    "\n",
    "  unlabeled_unos=list(set(unos)-set(indices_unos))\n",
    "  unlabeled_ceros=list(set(ceros)-set(indices_ceros))\n",
    "  unlabeled=unlabeled_unos+unlabeled_ceros\n",
    "  X_unlabeled_unos=np.array(data)[unlabeled_unos]\n",
    "  X_unlabeled_ceros=np.array(data)[unlabeled_ceros]\n",
    "\n",
    "  return (puntos_ceros,puntos_unos,X_unlabeled_ceros,X_unlabeled_unos,puntos_ceros_valid,puntos_unos_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817efff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_punto_stable_rank(punto,puntos_ceros,puntos_unos,mh0_00,mh0_11,mh0_01,mh0_10,mh1_00,mh1_11,mh1_01,mh1_10,distributions,number_instances,sample_size,contour=sr.standard_contour(),clustering_method=\"complete\",w_p=inf,w_q=1,reduced=True,p=2):\n",
    "    (mh0_00_p,mh0_11_p,mh0_01_p,mh0_10_p,mh1_00_p,mh1_11_p,mh1_01_p,mh1_10_p)=calcular_sranks_punto_v_muestra(punto,puntos_ceros,puntos_unos,distributions,number_instances,sample_size,contour=sr.standard_contour(),clustering_method=\"complete\",w_p=inf,w_q=1,reduced=True)\n",
    "    \n",
    "    \n",
    "    distance_cero=max(abs(mh0_00.lp_distance(mh0_00_p,p)),abs(mh0_10.lp_distance(mh0_10_p,p)))\n",
    "    distance_uno=max(abs(mh0_11.lp_distance(mh0_11_p,p)),abs(mh0_01.lp_distance(mh0_01_p,p)))\n",
    "\n",
    "        \n",
    "    if distance_cero>distance_uno:\n",
    "        clase=1\n",
    "    else:\n",
    "        clase=0\n",
    "    return clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1237c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_sranks_muestra(puntos_ceros,puntos_unos,sd_distribution,number_instances,sample_size,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True):\n",
    "    \n",
    "    n_ceros=len(puntos_ceros)\n",
    "    n_unos=len(puntos_unos)\n",
    "    distribution=sr.get_distribution(name=\"norm\", loc=0, scale=sd_distribution)\n",
    "    \n",
    "    ceros_distances=squareform(pdist(puntos_ceros,\"euclidean\"))\n",
    "    distance_ceros=sr.Distance(ceros_distances)\n",
    "    \n",
    "    unos_distances=squareform(pdist(puntos_unos,\"euclidean\"))\n",
    "    distance_unos=sr.Distance(unos_distances)\n",
    "    \n",
    "    ceros_wr_unos_distances=[]\n",
    "    for point in puntos_unos:\n",
    "        d_ceros_mod = squareform(pdist(np.array([point.tolist()]+puntos_ceros.tolist()), \"euclidean\"))\n",
    "        l=d_ceros_mod[0].tolist()\n",
    "        l.pop(0)\n",
    "        ceros_wr_unos_distances.append(l)\n",
    "    ceros_wr_unos_distances=np.array(ceros_wr_unos_distances)\n",
    "    \n",
    "    unos_wr_ceros_distances=[]\n",
    "    for point in puntos_ceros:\n",
    "        d_unos_mod = squareform(pdist(np.array([point.tolist()]+puntos_unos.tolist()), \"euclidean\"))\n",
    "        l=d_unos_mod[0].tolist()\n",
    "        l.pop(0)\n",
    "        unos_wr_ceros_distances.append(l)\n",
    "    unos_wr_ceros_distances=np.array(unos_wr_ceros_distances)\n",
    "    \n",
    "    h0_sr_00 = []\n",
    "    h1_sr_00 = []\n",
    "    h0_sr_11 = []\n",
    "    h1_sr_11 = []\n",
    "    h0_sr_01 = []\n",
    "    h1_sr_01 = []\n",
    "    h0_sr_10 = []\n",
    "    h1_sr_10 = []\n",
    "    mh0_00 = 0\n",
    "    mh1_00 = 0\n",
    "    mh0_11 = 0\n",
    "    mh1_11 = 0\n",
    "    mh0_01 = 0\n",
    "    mh1_01 = 0\n",
    "    mh0_10 = 0\n",
    "    mh1_10 = 0\n",
    "    for point in ceros_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_ceros.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_ceros.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_00.append(f)\n",
    "        h1_sr_00.append(g)\n",
    "        mh0_00 = mh0_00+f\n",
    "        mh1_00 = mh1_00+g\n",
    "\n",
    "    for point in unos_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_unos.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_unos.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_11.append(f)\n",
    "        h1_sr_11.append(g)\n",
    "        mh0_11 = mh0_11+f\n",
    "        mh1_11 = mh1_11+g\n",
    "\n",
    "    for point in ceros_wr_unos_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_ceros.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_ceros.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_01.append(f)\n",
    "        h1_sr_01.append(g)\n",
    "        mh0_01 = mh0_01+f\n",
    "        mh1_01 = mh1_01+g\n",
    "\n",
    "    for point in unos_wr_ceros_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_unos.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_unos.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_10.append(f)\n",
    "        h1_sr_10.append(g)\n",
    "        mh0_10 = mh0_10+f\n",
    "        mh1_10 = mh1_10+g\n",
    "\n",
    "    \n",
    "    mh0_00 = mh0_00/n_ceros\n",
    "    mh1_00 = mh1_00/n_ceros\n",
    "    mh0_11 = mh0_11/n_unos\n",
    "    mh1_11 = mh1_11/n_unos\n",
    "    mh0_01 = mh0_01/n_ceros\n",
    "    mh1_01 = mh1_01/n_ceros\n",
    "    mh0_10 = mh0_10/n_unos\n",
    "    mh1_10 = mh1_10/n_unos\n",
    "    \n",
    "    return (mh0_00,mh0_11,mh0_01,mh0_10,mh1_00,mh1_11,mh1_01,mh1_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d2c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_sranks_punto_v_muestra(punto,puntos_ceros,puntos_unos,sd_distribution,number_instances,sample_size,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True):\n",
    "    \n",
    "    n_ceros=len(puntos_ceros)\n",
    "    n_unos=len(puntos_unos)\n",
    "    distribution=sr.get_distribution(name=\"norm\", loc=0, scale=sd_distribution)\n",
    "    \n",
    "    ceros_distances=squareform(pdist(puntos_ceros,\"euclidean\"))\n",
    "    distance_ceros=sr.Distance(ceros_distances)\n",
    "    \n",
    "    unos_distances=squareform(pdist(puntos_unos,\"euclidean\"))\n",
    "    distance_unos=sr.Distance(unos_distances)\n",
    "    \n",
    "    ceros_wr_punto_distances=[]\n",
    "    d_ceros_mod = squareform(pdist(np.array([punto.tolist()]+puntos_ceros.tolist()), \"euclidean\"))\n",
    "    l=d_ceros_mod[0].tolist()\n",
    "    l.pop(0)\n",
    "    ceros_wr_punto_distances.append(l)\n",
    "    ceros_wr_punto_distances=np.array(ceros_wr_punto_distances)\n",
    "    \n",
    "    unos_wr_punto_distances=[]\n",
    "    d_unos_mod = squareform(pdist(np.array([punto.tolist()]+puntos_unos.tolist()), \"euclidean\"))\n",
    "    l=d_unos_mod[0].tolist()\n",
    "    l.pop(0)\n",
    "    unos_wr_punto_distances.append(l)\n",
    "    unos_wr_punto_distances=np.array(unos_wr_punto_distances)\n",
    "    \n",
    "    distance_ceros_mod=sr.Distance(d_ceros_mod)\n",
    "    distance_unos_mod=sr.Distance(d_unos_mod)\n",
    "    \n",
    "    h0_sr_00 = []\n",
    "    h1_sr_00 = []\n",
    "    h0_sr_11 = []\n",
    "    h1_sr_11 = []\n",
    "    h0_sr_01 = []\n",
    "    h1_sr_01 = []\n",
    "    h0_sr_10 = []\n",
    "    h1_sr_10 = []\n",
    "    mh0_00 = 0\n",
    "    mh1_00 = 0\n",
    "    mh0_11 = 0\n",
    "    mh1_11 = 0\n",
    "    mh0_01 = 0\n",
    "    mh1_01 = 0\n",
    "    mh0_10 = 0\n",
    "    mh1_10 = 0\n",
    "    for point in ceros_wr_punto_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_ceros_mod.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_ceros_mod.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_00.append(f)\n",
    "        h1_sr_00.append(g)\n",
    "        mh0_00 = f\n",
    "        mh1_00 = g\n",
    "\n",
    "    for point in unos_wr_punto_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_unos_mod.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_unos_mod.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_11.append(f)\n",
    "        h1_sr_11.append(g)\n",
    "        mh0_11 = f\n",
    "        mh1_11 = g\n",
    "\n",
    "    for point in ceros_wr_punto_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_ceros.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_ceros.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_01.append(f)\n",
    "        h1_sr_01.append(g)\n",
    "        mh0_01 = f\n",
    "        mh1_01 = g\n",
    "\n",
    "    for point in unos_wr_punto_distances:\n",
    "        p = distribution(point)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance_unos.get_h0sr(sample=s,contour=sr.standard_contour(),clustering_method=\"single\",w_p=inf,w_q=1,reduced=True)\n",
    "        b = distance_unos.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr_10.append(f)\n",
    "        h1_sr_10.append(g)\n",
    "        mh0_10 = f\n",
    "        mh1_10 = g\n",
    "        \n",
    "\n",
    "    \n",
    "    return (mh0_00,mh0_11,mh0_01,mh0_10,mh1_00,mh1_11,mh1_01,mh1_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba59173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_puntos(data,target,sd_distribution,number_instances,sample_size,contour=sr.standard_contour(),w_p=inf,w_q=1,reduced=True,p=2,th=0,clustering_method=\"single\",reduccion=False):\n",
    "    (puntos_ceros,puntos_unos,X_unlabeled_ceros,X_unlabeled_unos,X_unlabeled_ceros_valid,X_unlabeled_unos_valid)=preparar_dataset(data,target)\n",
    "    embedding=data\n",
    "    if reduccion==True:\n",
    "        embedding=umap.UMAP(random_state=75).fit_transform(data)\n",
    "    (puntos_ceros_umap,puntos_unos_umap,X_unlabeled_ceros_umap,X_unlabeled_unos_umap,X_unlabeled_ceros_valid_umap,X_unlabeled_unos_valid_umap)=preparar_dataset(embedding,target)\n",
    "\n",
    "\n",
    "    bien=0\n",
    "    mal=0\n",
    "    dudoso=0\n",
    "\n",
    "    puntos_ceros_final=puntos_ceros.tolist()\n",
    "    puntos_unos_final=puntos_unos.tolist()\n",
    "    puntos_dudosos_final=[]\n",
    "\n",
    "    (mh0_00,mh0_11,mh0_01,mh0_10,mh1_00,mh1_11,mh1_01,mh1_10)=calcular_sranks_muestra(puntos_ceros_umap,puntos_unos_umap,sd_distribution,number_instances,sample_size,contour,clustering_method,w_p,w_q,reduced)\n",
    "\n",
    "    \n",
    "\n",
    "    for i,punto in enumerate(X_unlabeled_unos_umap):\n",
    "        clase=analizar_punto_stable_rank(punto,puntos_ceros_umap,puntos_unos_umap,mh0_00,mh0_11,mh0_01,mh0_10,mh1_00,mh1_11,mh1_01,mh1_10,sd_distribution,number_instances,sample_size,contour,clustering_method,w_p,w_q,reduced,p)\n",
    "        if clase==1:\n",
    "          bien=bien+1\n",
    "          puntos_unos_final.append(X_unlabeled_unos[i])\n",
    "        elif clase==0:\n",
    "          mal=mal+1\n",
    "          puntos_ceros_final.append(X_unlabeled_unos[i])\n",
    "        else:\n",
    "          dudoso=dudoso+1\n",
    "          puntos_dudosos_final.append(X_unlabeled_unos[i])\n",
    "\n",
    "\n",
    "\n",
    "    for i,punto in enumerate(X_unlabeled_ceros_umap):\n",
    "        clase=analizar_punto_stable_rank(punto,puntos_ceros_umap,puntos_unos_umap,mh0_00,mh0_11,mh0_01,mh0_10,mh1_00,mh1_11,mh1_01,mh1_10,sd_distribution,number_instances,sample_size,contour,clustering_method,w_p,w_q,reduced,p)\n",
    "        if clase==1:\n",
    "          mal=mal+1\n",
    "          puntos_unos_final.append(X_unlabeled_ceros[i])\n",
    "        elif clase==0:\n",
    "          bien=bien+1\n",
    "          puntos_ceros_final.append(X_unlabeled_ceros[i])\n",
    "        else:\n",
    "          dudoso=dudoso+1\n",
    "          puntos_dudosos_final.append(X_unlabeled_ceros[i])\n",
    "\n",
    "    comprobar_accuracy(np.array(puntos_ceros_final),np.array(puntos_unos_final),X_unlabeled_ceros_valid,X_unlabeled_unos_valid)\n",
    "\n",
    "    return (bien, mal,dudoso,np.array(puntos_ceros_final),np.array(puntos_unos_final),np.array(puntos_dudosos_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a3b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def comprobar_accuracy(puntos_ceros_final,puntos_unos_final,X_unlabeled_ceros_valid,X_unlabeled_unos_valid):\n",
    "    datos=np.concatenate((puntos_ceros_final,puntos_unos_final),axis=0)\n",
    "    labels=np.concatenate((np.zeros(puntos_ceros_final.shape[0]),np.ones(puntos_unos_final.shape[0])))\n",
    "\n",
    "    modelSVMLineal = SVC(kernel=\"linear\",probability=True,random_state=90)\n",
    "    modelSVMLineal.fit(datos, labels)\n",
    "\n",
    "    mal=np.count_nonzero(modelSVMLineal.predict(X_unlabeled_ceros_valid)!=0)\n",
    "    mal=mal+np.count_nonzero(modelSVMLineal.predict(X_unlabeled_unos_valid)!=1)\n",
    "    total=X_unlabeled_ceros_valid.shape[0]+X_unlabeled_unos_valid.shape[0]\n",
    "    print(\"--------------Clasificador SVM--------------\")\n",
    "    resumen(total-mal,mal,0)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # datos=np.concatenate((puntos_ceros_final,puntos_unos_final),axis=0)\n",
    "    # labels=np.concatenate((np.zeros(puntos_ceros_final.shape[0]),np.ones(puntos_unos_final.shape[0])))\n",
    "\n",
    "    modelRandomForest = RandomForestClassifier(random_state=90)\n",
    "    modelRandomForest.fit(datos, labels)\n",
    "\n",
    "    mal=np.count_nonzero(modelRandomForest.predict(X_unlabeled_ceros_valid)!=0)\n",
    "    mal=mal+np.count_nonzero(modelRandomForest.predict(X_unlabeled_unos_valid)!=1)\n",
    "    total=X_unlabeled_ceros_valid.shape[0]+X_unlabeled_unos_valid.shape[0]\n",
    "    print(\"-------------- Clasificador Random Forest--------------\")\n",
    "    resumen(total-mal,mal,0)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f3387bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen(bien,mal,dudosos):\n",
    "  print('-----------------RESUMEN------------------')\n",
    "  print('Bien anotados '+str(bien))\n",
    "  print('Mal anotados '+str(mal))\n",
    "  print('Sin anotar '+str(dudosos))\n",
    "  print('')\n",
    "  if bien+mal!=0:\n",
    "    print('Porcentaje correcto '+str(bien/(bien+mal)))\n",
    "  else:\n",
    "    print('Porcentaje correcto 0')\n",
    "  print('Porcentaje anotado '+str((bien+mal)/(bien+mal+dudosos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c5e73",
   "metadata": {},
   "source": [
    "# Standard unreduced stable rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afc4d8",
   "metadata": {},
   "source": [
    "## No threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ab8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data,target) = load_prima()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e50f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=min(data[:,0])\n",
    "l2=min(data[:,1])\n",
    "l3=max(data[:,0])\n",
    "l4=max(data[:,1])\n",
    "\n",
    "s1=((l3-l1)/2+(l4-l2)/2)/2\n",
    "s1\n",
    "s2=s1/2\n",
    "s3=1.5*s1\n",
    "s4=2*s1\n",
    "s5=0.1\n",
    "\n",
    "number_instances=100\n",
    "sample_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea35177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Clasificador SVM--------------\n",
      "-----------------RESUMEN------------------\n",
      "Bien anotados 21\n",
      "Mal anotados 10\n",
      "Sin anotar 0\n",
      "\n",
      "Porcentaje correcto 0.6774193548387096\n",
      "Porcentaje anotado 1.0\n",
      "\n",
      "-------------- Clasificador Random Forest--------------\n",
      "-----------------RESUMEN------------------\n",
      "Bien anotados 15\n",
      "Mal anotados 16\n",
      "Sin anotar 0\n",
      "\n",
      "Porcentaje correcto 0.4838709677419355\n",
      "Porcentaje anotado 1.0\n",
      "\n",
      "-----------------RESUMEN------------------\n",
      "Bien anotados 67\n",
      "Mal anotados 60\n",
      "Sin anotar 0\n",
      "\n",
      "Porcentaje correcto 0.5275590551181102\n",
      "Porcentaje anotado 1.0\n"
     ]
    }
   ],
   "source": [
    "(bien,mal,dudoso,pcero,puno,pdudoso)=analizar_puntos(data,target,s2,number_instances,sample_size)\n",
    "resumen(bien,mal,dudoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d27a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
